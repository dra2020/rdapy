---
layout: page
title: High-Volume Offline Scoring
permalink: scoring/
---

A command-line interface provides a set of scripts that enable you to "score" large collections of plans in bulk.
This is useful for scoring ensembles of plans, e.g., generated by ReCom.
These scripts are in the `scripts` directory.

### Input Data

The data & shapes used by this scoring toolchain are [Dave's Redistricting](https://davesredistricting.org/) (DRA) [GeoJSON files](TODO).
The specifics of that format are described there.
The frontend data-processing scripts here depend on that custom GeoJSON format.

### Scores (Metrics)

This toolchain computes several dozen metrics described in [Scores (Metrics)]({{ '/scores' | prepend: site.baseurl }}).
It produces a CSV file with one row of plan-level scores per plan and
a JSONL file with one row of district-level aggregates per plan.

The plan-level scores include most of the analytics computed in the DRA app.
A few are not included for various reasons:

*   Jon Eguia's geographic baseline & advantage measures are implemented in the DRA client,
    as opposed to the in the `dra-analytics` package (because of the information needed to compute them),
    so that is not included here.
*   "Know it when you see it" (KIWYSI) compactness (see [Compactness](https://medium.com/dra-2020/compactness-8e0ee3851126))
    is very expensive, so it's not included here. The straightforward way to calculate compactness metrics for a plan is, of course, to first create district shapes based on the precinct assignments and then compute the metrics using those shapes. Unfortunately, the simple naive approach to creating district shapes — “dissolving” precinct shapes into district shapes — is a very expensive operation. Even with just precinct shapes (i.e., not blocks), that can take ~60 seconds for a North Carolina plan. Traditional compactness measures of Reock and Polsby-Popper can be computed quickly using pre-computed shapes attributes without actually having district shapes.

The scores here also include several metrics not yet in the DRA app, including:

*   In the proportionality/partisan category, there are two efficiency gap variations: 
    `efficiency_gap_wasted_votes` and `efficiency_gap_statewide` 
    to complement the statewide fractional seats version in DRA.
*   In the competitiveness category, there is a simple count of the number of districts in the 0.45-0.55 range,
    `competitive_district_count`, and the average margin of victor, `average_margin`.
*   In the minority opportunity category, there majority-minority district counts for Blacks alone, Hispanics alone, and 
    Black & Hispanic coalition districts: `mmd_black`, `mmd_hispanic`, and `mmd_coalition`.
*   In the compactness category, `cut_score` is a discrete geometry measure of compactness.
    The sibling `spanning_tree_score` is *not* computed though, as it is also very expensive.
    There's also a "population compactness" or "energy" score.
*   Finally, in the county-district splitting category, there are simple counts of the numbers of counties split
    as well as the number times counties are split.

### SCORE.sh

This example bash script shows how to take an ensemble of plans, a DRA geojson file, and an adjacency graph, and 
generate a CSV file of scores and a JSONL file of by-district measures.
It uses 2020 census, VAP, and CVAP data from geojson, as well as the 2016-2020 election composite.
Only one election is scored at this time.

```bash
scripts/SCORE.sh \
--state xx \
--plan-type congress \
--geojson path/to/DRA.geojson \
--graph path/to/adjacency_graph.json \
--plans path/to/plans.jsonl \
--scores path/to/scores.csv \
--by-district path/to/by-district.jsonl
```

where:

*   The state is a two-character state code.
*   The `plan-type` is `congress`, 'upper`, or `lower`, for upper and lower state house.
*   The `geojson` is a DRA precinct GeoJSON file with data coded by dataset.
    An example is provided in `testdata/data/NC_vtd_datasets.geojson`.
*   The `graph` is a JSON file that contains the node/list of neighbors adjacency graph of the precincts.
    An example is provided in `testdata/intermediate/NC_graph.json`.
*   The `plans` is a JSONL file that contains the ensemble of plans to be scored.
    The plans can be simple dictionaries of geoid:district assignments, or
    they can be tagged 'plan' records in the ensemble format used by `rdatools/rdatools` and `rdatools/rdautils`.
    An example of the latter is provided in `testdata/plans/NC_congress_plans.tagged.jsonl`.

The script writes a set of plan-level scores to a CSV file
a set of by-district measures to a JSONL file, and 
metadata for the scores in a JSON file.
Examples of these files can be found in `testdata/examples/`.

The plan-level scores are described in [Scores (Metrics)]({{ '/scores' | prepend: site.baseurl }}).

*Note: This scripts does not extract an adjacency graph from the GeoJSON.
It uses a pre-computed adjacency graph from DRA.*

By default, this script calculates all metrics ("scores") for all plans in an input ensemble.
If your ensembles are very large though, you can [increase scoring throughput]({{ '/throughput' | prepend: site.baseurl }})
by breaking the overall process down into pieces and running them in parallel.

### Component Scripts

If you want more fine-grained control over the scoring process,
you can use these component scripts directly.

#### Extracting an Adjacency Graph from a GeoJSON

This script extracts an adjacency graph from a DRA GeoJSON file.

```bash
scripts/extract_graph.py \
--geojson path/to/DRA.geojson \
--graph path/to/adjacency_graph.json
```

*Note: This script can read a CSV file that contains more precinct-to-precinct adjacencies to add to the graph,
"mods" for ["operational contiguity"](https://medium.com/dra-2020/contiguity-20f23ea15969).*

#### Mapping Scoring Data to a DRA GeoJSON

This script maps the data needed for scoring plans to the data in a DRA GeoJSON file.
The specific datasets used can be specified as optional arguments.
The default datasets are the 2020 census, VAP, and CVAP data,
and the composite election dataset for 2016-2020 elections.

```bash
scripts/map_scoring_data.py \
--geojson path/to/DRA.geojson \
--data-map path/to/data_map.json
```

#### Extracting Data from a DRA GeoJSON

This script extracts data from a DRA GeoJSON file and writes it to a JSONL file,
using the data map to determine what data to extract.

```bash
scripts/extract_data.py \
--geojson path/to/DRA.geojson \
--data-map path/to/data_map.json \
--graph path/to/adjacency_graph.json \
--data path/to/input_data.jsonl
```

#### Aggregating Plans by District

This script reads a stream of plans from STDIN, aggregates data & shapes by district,
and writes the plan and the aggregates to STDOUT.

```bash
cat path/to/plans.jsonl \
| scripts/aggregate.py \
--state xx \
--plan-type congress \
--data path/to/input_data.jsonl \
--graph path/to/adjacency_graph.json > path/to/plans_plus_aggregates.jsonl
```

This script reads plans as JSONL from the input stream.
Each plan can be a simple dictionary of geoid:district assignments, or
a tagged format with the `"_tag_"` tag equal to `"plan"` and the `"plan"` key containing the geoid:district pairs.
Examples of these formats can be found in `testdata/plans/` in `NC_congress_plans.naked.jsonl` and `NC_congress_plans.tagged.jsonl`, respectively.

If the JSON records are in tagged format, metadata records are passed through unchanged, 
as are any other records.

In addition to any records simply passed through, the output stream contains a record for each plan with
the geoid:district assignments in the `"plan"` key and the district-level aggregates in the `"aggregates"` key. 
Aggregates hierarchically encode the type of dataset (census, vap, cvap, election, shape), 
the dataset key (defined by DRA in the README for the GeoJSON), the aggregate name (e.g., "dem_by_district"), and 
the aggregates by district. For example:

`"election": {"E_16-20_COMP": {"dem_by_district": [...]`.

The first item in each list is a state-level aggregate, and the rest are district-level aggregates for districts 1 to N.

You can see an example in `testdata/intermediate/NC_congress_aggs.100.v4.jsonl`.

There are some helper scripts to convert [alternative formats]({{ '/formats' | prepend: site.baseurl }}) 
into the tagged format that can be ingested by the `aggregate.py` script.

#### Scoring Plans

This script reads a stream of plans with district aggregates from STDIN,
scores the plans, and writes the plan-level scores to STDOUT along with
the district-level aggregates.

```bash
cat path/to/plans_plus_aggregates.jsonl \
| scripts/score.py \
--state xx \
--plan-type congress \
--data path/to/input_data.jsonl \
--graph path/to/adjacency_graph.json > path/to/scores_plus_aggregates.jsonl
```

#### Write Scores to Disk

This script reads a stream of scores with district aggregates from STDIN,
and writes the plan-level scores to a CSV file and the district-level aggregates to a JSONL file.

```bash
cat path/to/scores_plus_aggregates.jsonl \
| scripts/write.py \
--data path/to/input_data.jsonl \
--scores path/to/scores.csv \
--by-district path/to/by-district.jsonl
```

If you want output in a different format, you can process the output of the `score.py` script directly, 
e.g., using `jq`.
