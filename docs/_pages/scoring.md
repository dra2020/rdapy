---
layout: page
title: High-Volume Offline Scoring
permalink: scoring/
---

A command-line interface provides a set of scripts that enable you to "score" large collections of plans in bulk.
This is useful for scoring ensembles of plans, e.g., generated by ReCom.
These scripts are in the `scripts` directory.

### SCORE.sh

This example bash script takes an ensemble of plans, a DRA geojson file, and an adjacency graph, and 
generates a CSV file of scores and a JSONL file of by-district measures.
By default, it uses 2020 census, VAP, and CVAP data from geojson, as well as the 2016-2020 election composite.
Only one election is scored at this time.

```bash
scripts/SCORE.sh \
--state xx \
--plan-type congress \
--geojson path/to/DRA.geojson \
--graph path/to/adjacency_graph.json \
--plans path/to/plans.jsonl \
--scores path/to/scores.csv \
--by-district path/to/by-district.jsonl
```

where:

*   The state is a two-character state code.
*   The `plan-type` is `congress`, 'upper`, or `lower`, for upper and lower state house.
*   The `geojson` is a [Dave's Redistricting](https://davesredistricting.org/) (DRA) precinct GeoJSON file with data coded by dataset.
    An example is provided in `testdata/data/NC_vtd_datasets.geojson`.
*   The `graph` is a JSON file that contains the node/list of neighbors adjacency graph of the precincts.
    An example is provided in `testdata/intermediate/NC_graph.json`.
*   The `plans` is a JSONL file that contains the ensemble of plans to be scored.
    The plans can be simple dictionaries of geoid:district assignments, or
    they can be tagged 'plan' records in the ensemble format used by `rdatools/rdatools` and `rdatools/rdautils`.
    An example of the latter is provided in `testdata/plans/NC_congress_plans.tagged.jsonl`.

The script writes a set of plan-level scores to a CSV file
a set of by-district measures to a JSONL file, and 
metadata for the scores in a JSON file.
Examples of these files can be found in `testdata/scoring/`.

The plan-level scores are described in [Scores (Metrics)]({{ '/scores' | prepend: site.baseurl }}).

*Note: This scripts does not extract an adjacency graph from the GeoJSON.
It uses a pre-computed adjacency graph from DRA.*

By default, this script calculates all metrics ("scores") for all plans in an input ensemble.
If your ensembles are very large though, you can [increase scoring throughput]({{ '/throughput' | prepend: site.baseurl }}),
by breaking the overall process down into pieces and running them in parallel.

### Component Scripts

If you want more fine-grained control over the scoring process,
you can use these component scripts directly.

#### Extracting an Adjacency Graph from a GeoJSON

This script extracts an adjacency graph from a DRA GeoJSON file.

```bash
scripts/extract_graph.py \
--geojson path/to/DRA.geojson \
--graph path/to/adjacency_graph.json
```

*Note: This script can read a CSV file that contains more precinct-to-precinct adjacencies to add to the graph,
"mods" for ["operational contiguity"](https://medium.com/dra-2020/contiguity-20f23ea15969).*

#### Mapping Scoring Data to a DRA GeoJSON

This script maps the data needed for scoring plans to the data in a DRA GeoJSON file.
The specific datasets used can be specified as optional arguments.

```bash
scripts/map_scoring_data.py \
--geojson path/to/DRA.geojson \
--data-map path/to/data_map.json
```

#### Extracting Data from a DRA GeoJSON

This script extracts data from a DRA GeoJSON file and writes it to a JSONL file,
using the data map to determine what data to extract.

```bash
scripts/extract_data.py \
--geojson path/to/DRA.geojson \
--data-map path/to/data_map.json \
--graph path/to/adjacency_graph.json \
--data path/to/input_data.jsonl
```

#### Aggregating Plans by District

This script reads a stream of plans from STDIN, aggregates data & shapes by district,
and writes the plan and the aggregates to STDOUT.

```bash
cat path/to/plans.jsonl \
| scripts/aggregate.py \
--state xx \
--plan-type congress \
--data path/to/input_data.jsonl \
--graph path/to/adjacency_graph.json > path/to/plans_plus_aggregates.jsonl
```

This script reads plans as JSONL from the input stream.
Each plan can be a simple dictionary of geoid:district assignments, or
a tagged format with the `"_tag_"` tag equal to `"plan"` and the `"plan"` key containing the geoid:district pairs.
Examples of these formats can be found in `testdata/plans/` in `NC_congress_plans.naked.jsonl` and `NC_congress_plans.tagged.jsonl`, respectively.

If the JSON records are in tagged format, metadata records are passed through unchanged, 
as are any other records.

In addition to any records simply passed through, the output stream contains a record for each plan with
the geoid:district assignments in the `"plan"` key and the district-level aggregates in the `"aggregates"` key. 
Aggregates hierarchically encode the type of dataset (census, vap, cvap, election, shape), 
the dataset key (defined by DRA in the README for the GeoJSON), the aggregate name (e.g., "dem_by_district"), and 
the aggregates by district. For example:

`"election": {"E_16-20_COMP": {"dem_by_district": [...]`.

The first item in each list is a state-level aggregate, and the rest are district-level aggregates for districts 1 to N.

You can see an example in `testdata/scoring/NC_congress_aggs.100.v4.jsonl`.

**Helpers**

Two helper scripts make it easy to use other input formats, instead of the two described above.

This script takes a JSON file that has a `"plan"` key with a list of geoid:district assignment dictionaries and
produces a stream of JSON tagged records that can be input to the `aggregate.py` script.

```bash
scripts/from_json.py \
--input testdata/plans/NC_congress_plans.legacy.json
```

An example of this format can be found in `testdata/plans/` in `NC_congress_plans.legacy.json`.

Similarly, this script takes a list of CSV files, or a wildcard pattern for CSV files in a directory, and
synthesizes a stream of JSON tagged records that can be input to the `aggregate.py` script.

```bash
scripts/from_csvs.py \
--files testdata/plans/csvs/NC_congress.*.csv
```

An example of this are the CSV files in `testdata/plans/csvs/`.

#### Scoring Plans

This script reads a stream of plans with district aggregates from STDIN,
scores the plans, and writes the plan-level scores to STDOUT along with
the district-level aggregates.

```bash
cat path/to/plans_plus_aggregates.jsonl \
| scripts/score.py \
--state xx \
--plan-type congress \
--data path/to/input_data.jsonl \
--graph path/to/adjacency_graph.json > path/to/scores_plus_aggregates.jsonl
```

#### Write Scores to Disk

This script reads a stream of scores with district aggregates from STDIN,
and writes the plan-level scores to a CSV file and the district-level aggregates to a JSONL file.

```bash
cat path/to/scores_plus_aggregates.jsonl \
| scripts/write.py \
--data path/to/input_data.jsonl \
--scores path/to/scores.csv \
--by-district path/to/by-district.jsonl
```

If you want output in a different format, you can process the output of the `score.py` script directly, 
e.g., using `jq`.
